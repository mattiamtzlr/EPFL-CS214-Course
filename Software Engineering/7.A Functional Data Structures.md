#software-engineering #scala #data-structures 

# Structure Sharing and Path Copying
The following function
```Scala
abstract class IntSet
case class Empty() extends IntSet
case class Node(left: IntSet, elem: Int, right: IntSet) extends IntSet

def mkTree(n: Int): IntSet =
  if n <= 0 then Empty()
  else
    val t1: IntSet = mkTree(n - 1)
    Node(t1, n, t1)
```
has time complexity of $O(n)$ as the left and right child of a `Node` object are always equal. Thus the run time is *linear*.

However, the following method 
```Scala
extension (s: IntSet)
  def size: Int = s match
    case Empty() => 0
    case Node(l, _, r) => l.size + 1 + r.size
```
has time complexity of $O(n^2)$ as it has to go through every single child to compute its length. Thus the run time is *exponential*.

This raises the question: **How can we *construct* a tree faster than we can compute its *size*?**

## Structure Sharing
These trees, as defined above, are, in fact, *acyclic graphs*, meaning that they can be drawn like this:
```
IntSet(e1, e2, e3):
  ┌─ e1 ─┐
  │      │
  ├─ e2 ─┤
  │      │
  └─ e3 ─┘
```
Thus, as the left and right child of each node are exactly the same, we don't have to compute both *structures*, we can *share* them.
This is why it is faster to construct a tree, than it is to compute its size.

### Concatenated Lists
In the same spirit, the following code
```Scala
val a = (1 to p).toList      // for some integer p
val b = (1 to q).toList ++ a // for some integer q
```
uses only $p + q$ memory units, as $p$ units are shared between list `a` and list `b`.
<br>

# Specifications of Data Structures
Up until now we have seen the [[2.3 Data and Classes#`require`|require]] precondition and the [[4.B Testing Techniques#5. Pre/Post Conditions|ensuring]] postcondition, which *specify* the contract of a function.

`require` is a requirement for code to be able to call the function and must be met by the caller.

`ensuring` checks a property of the body that it wraps and it must be met by the function. 
However, `ensuring` only needs to hold if `require` was true.

In math: $\forall x \in A, \; pre(x) \rightarrow post(x, body)$

## Data Structure Invariants
An *invariant* on a data structure restricts valid elements of a type, meaning it is a property of the data structure which is maintained by all (completed) data structure operations.

It must be
- true for initial values (e.g. empty lists, tree leaves), and
- preserved by all operations,

It represents a refinement of a type, for example a *sorted* list instead of a normal list.
This also means that any method using that structure, must respect this refinement, for instance an `insert` method should maintain `isSorted` on a list.

Invariants are expressed by the following:
- state the property in both `require` *and* `ensuring`.
- use `require` on the class constructor.

## Abstraction Functions
Often, a data structure is specified by mapping it to a *simpler data structure*. A function which performs such a mapping is called an *abstraction function*.
An example of this would be to convert a `Tree` to a `List`.
<br>

# Relationships between Collections
1. strictly sorted sequence <=> set
   ```
   List(10, 30, 70) <=> Set(10, 30, 70)
   ```
   <br>
2. non-strictly sorted sequence <=> bag (multiset)
   ```
   List(10, 30, 30, 70) <=> Multiset(10, 30, 30, 70)
   ```
   <br>
3. Map[K, V] <=> Set[(K, V)] where no two (k, v1), (k, v2) in set
   ```
   Map(1 -> 'x', 2 -> 'y') <=> Set((1, 'x'), (2, 'y'))
   ```
   <br>
4. Bag[T] <=> Map[T, Int] with positive values
   ```
   Bag(10, 30, 30, 70) <=> Map(10 -> 1, 30 -> 2, 70 -> 1)
   ```
   <br>
5. sequence is a map with [0, n - 1] as a domain
   ```
   List(10, 30, 70) <=> Map(0 -> 10, 1 -> 30, 2 -> 70)
   ```

If we use one of these conversions, we also have to make sure to define all methods correctly to respect possible invariants.
<br>

# Complete Example: Trees with Concatenation
See slides 23 - 48 for a complete example of the above concepts being applied:
![[soft-eng-week7.pdf#page=23]]